# 概述

我们可以将神经网络的开发与工作模式抽象为以下几个步骤：

ThreadsPerBlock和Blocks的数量受哪些条件约束。  
理论占用率怎么计算？  
什么是warp，什么是warp divergence？  
cuda的内存模型里有多少种memory，它们的位置(片上还是板上)，带宽和延迟的相对大小？  
global memory的访存合并是什么？  
什么样的变量会被分配在register上？什么样的变量会被分配在local memory上？  
Block是怎么被SM调度执行的？  
什么是cuda core？什么是tensor core？  
什么是bank conflict？怎么避免bank conflict，你能想到多少方法？  
描述一下Block reduce的大致实现。  
描述一下double buffer(ping pong buffer）的大概原理和实现。  
什么是roofline model？什么是memory bound，什么是computation bound？  
kernel fusion为什么能提升性能？还有哪些好处？举几个fusion的例子。  
gpu上有分支预测吗？gpu上有指令集并行吗？  
常用profile工具和方法。  
float的计算一定比int消耗更多的cycle吗(主要是加法和乘法）？  
常见的float格式。fp32，tf32，fp16，bf16的联系和区别？  
ptx和sass是什么，和cuda的关系？  
cuda上的排序和topk算法原理和实现。  
matmul的优化，超级加分题。  
flash attention的优化，超级加分题。