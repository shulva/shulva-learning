# CUDA内存

CPU 和 GPU 中都有内存分级的设计。相对于 CPU 编程来说，CUDA 编程模型向程序员提供更多的控制权。

![](../../../../files/images/MLsys/13-e-1.png)
表列出了 CUDA 中的几种内存和它们的主要特征。这些特征包括物理位置、设备 的访问权限、可见范围及对应变量的生命周期。

![](../../../../files/images/MLsys/13-e-2.png)

### 全局内存

这里“全局内存”（global memory）的含义是核函数中的所有线程都能够访问其中的数据，和 C++中的**全局变量**不是一回事。

全局内存由于没有存放在 GPU 的芯片上，因此具有较高的延迟和较低的访问速度。然而，它的容量是所有设备内存中最大的。其容量基本上就是显存容量。

全局内存的主要角色是为核函数提供数据，并在主机与设备及设备与设备之间传递数据:`cudaMalloc(),cudaMemcpy()..`。

全局内存**对整个网格的所有线程可见**。也就是说，一个网格的所有线程都可以访问（读或写）传入核函数的设备指针所指向的全局内存中的全部数据。

**全局内存的生命周期（lifetime）不是由核函数决定的，而是由主机端决定的**。在之前数组相加的例子中，由指针`d_x、d_y 和 d_z` 所指向的全局内存缓冲区的生命周期就是从主机端用 `cudaMalloc` 对它们分配内存开始，到主机端用 `cudaFree` 释放它们的内存结束。在这期间，可以在相同的或不同的核函数中多次访问这些全局内存中的数据。

---

我们前面介绍的全局内存变量都是动态地分配内存的。在 CUDA 中允许使用静态全局内存变量，其所占内存数量是在编译期间就确定的。而且，这样的静态全局内存变量必须在所有主机与设备函数外部定义，所以是一种“全局[^1]的静态全局内存变量”。

下列代码表明了静态全局内存变量的一些特点：[^2]

```cpp
#include "error.cuh"
#include <stdio.h>

//修饰符 __device__ 说明该变量是设备中的变量，而不是主机中的变量
__device__ int d_x = 1; //静态全局内存变量
__device__ int d_y[2];

//在核函数中，可直接对静态全局内存变量进行访问，不需要以传参形式传递
void __global__ my_kernel(void)
{
    d_y[0] += d_x;
    d_y[1] += d_x;
    printf("d_x = %d, d_y[0] = %d, d_y[1] = %d.\n", d_x, d_y[0], d_y[1]);
}

// 不可在主机函数中直接访问静态全局内存变量，
// 但可以用 cudaMemcpyToSymbol函数和cudaMemcpyFromSymbol函数 
// 在静态全局内存与主机内存之间传输数据。
int main(void)
{
    int h_y[2] = {10, 20};
    CHECK(cudaMemcpyToSymbol(d_y, h_y, sizeof(int) * 2));
    
    my_kernel<<<1, 1>>>();
    CHECK(cudaDeviceSynchronize());
    
    CHECK(cudaMemcpyFromSymbol(h_y, d_y, sizeof(int) * 2));
    printf("h_y[0] = %d, h_y[1] = %d.\n", h_y[0], h_y[1]);
    
    return 0;
}

```

### 常量内存

常量内存（constant memory）是有常量缓存的全局内存，数量有限，一共仅有 64 KB。 它的可见范围和生命周期与全局内存一样。不同的是，常量内存仅可读、不可写。

由于有缓存，常量内存的访问速度比全局内存高，但得到高访问速度的前提是一个线程束中的线程（一个线程块中相邻的 32 个线程）要读取相同的常量内存数据。

> [!question] 为什么？
> 当一个线程束（Warp，通常是32个线程）中的所有线程访问**同一个地址**时，常量内存的性能最高。数据会被**广播（Broadcast）**到所有线程，只需一次内存读取。如果线程访问不同的地址，访问会被序列化，性能会下降。
> 

一个使用常量内存的方法是在核函数外面用`__constant__` 定义变量，并用 cudaMemcpyToSymbol 将数据从主机端复制到设备的常量内存后供核函数使用。

```cpp
__constant__ float d_factors[NUM_FACTORS];
float h_factors[NUM_FACTORS] = {10.0f, 20.0f, 30.0f, 40.0f};
cudaMemcpyToSymbol(d_factors, h_factors, factors_size);
// 在核函数内部可以像访问普通数组一样直接读取 d_factors。
```

给核函数传递的参数（传值方式）就存放在常量内存中，但给核函数传递参数最多只能在一个核函数中使用4 KB常量内存。

```cpp
const int N = 100000001;

void __global__ add(const double *x,double *z, const int N)  {if (n < N){...}}
```

在核函数中的代码段 if (n < N) 中，这个参数 N 就被每一个线程使用了。所以，核函数中的每一个线程都知道该变量的值，而且对它的访问比对全局内存的访问要快。

### 纹理内存和表面内存[^3]

纹理内存（texture memory）和表面内存（surface memory）类似于常量内存，也是一种具有缓存的全局内存，有相同的可见范围和生命周期，而且一般仅可读（表面内存也可写）。不同的是，纹理内存和表面内存容量更大，而且使用方式和常量内存也不一样。
### 寄存器

在核函数中定义的不加任何限定符的变量一般来说就存放于寄存器（register）中。 核函数中定义的不加任何限定符的数组有可能存放于寄存器中，但也有可能存放于局部内存中。

以前提到过的各种内建变量，如 gridDim、blockDim、blockIdx、 threadIdx 及 warpSize 都保存在特殊的寄存器中。在核函数中访问这些内建变量是很高效的。

```cpp
const int n = blockDim.x * blockIdx.x + threadIdx.x;
```

寄存器变量仅仅被一个线程可见。也就是说，每一个线程都有一个变量 n 的副本。虽然在核函数的代码中用了这同一个变量名，但是不同的线程中该寄存器变量的值是可以不同的。

每个线程都只能对它的副本进行读写。寄存器的生命周期也与所属线程的生命周期一致，从定义它开始，到线程消失时结束。

寄存器内存在芯片上（on-chip），是所有内存中访问速度最高的，但是其数量也很有限。

### 局部内存

我们还没有用过局部内存（local memory），但从用法上看，局部内存和寄存器几乎一样。核函数中定义的不加任何限定符的变量有可能在寄存器中，也有可能在局部内存中。寄存器中放不下的变量，以及索引值不能在编译时就确定的数组，都有可能放在局部内存中。 这种判断是由编译器自动做的。

虽然局部内存在用法上类似于寄存器，但从硬件来看，局部内存只是全局内存的一部分。所以，局部内存的延迟相比寄存器来说更高。

每个线程最多能使用高达 512 KB 的局部内存，但使用过多会降低程序的性能。

### 共享内存

我们还没有使用过共享内存（shared memory）。共享内存和寄存器类似，存在于芯片上，具有仅次于寄存器的读写速度，数量也有限。

不同于寄存器的是，共享内存对整个**线程块**可见，其生命周期也与整个线程块一致。也就是说，每个线程块拥有一个共享内存变量的副本。

共享内存变量的值在不同的线程块中可以不同。一个线程块中的所有线程都可以访问该线程块的共享内存变量副本，但是不能访问其他线程块的共享内存变量副本。

共享内存的主要作用是减少对全局内存的访问，或者改善对全局内存的访问模式。

### L1与L2缓存

从费米架构开始，有了 SM 层次的 L1 缓存（一级缓存）和设备（一个设备有多个 SM） 层次的 L2 缓存（二级缓存）。它们主要用来**缓存全局内存和局部内存**的访问，减少延迟。

从编程的角度来看，共享内存是可编程的缓存（共享内存的使用完全由用户操控），而 L1 和 L2 缓存是不可编程的缓存（用户最多能引导编译器做一些选择）。

### SM占有率

因为一个 SM 中的各种计算资源是有限的，那么有些情况下一个 SM 中驻留的线程数目就有可能达不到理想的最大值。

当并行规模较小时，有些 SM 可能就没有被利用，占有率为零。这是导致程序性能低下的原因之一。当并行规模足够大时，也有可能得到非 100% 的占有率，这就是下面要讨论的情形。[^4]

![](../../../../files/images/MLsys/13-e-3.png)

- **寄存器和共享内存使用量很少的情况**：此时，SM 的占有率完全由执行配置中的线程块大小决定。关于线程块大小，由于在执行核函数中的指令时，不完整的线程束花的时间和完整的线程束花的时间一样，所以，建议将线程块大小取为 32 的整数倍。

- **有限的寄存器个数对占有率的约束情况**:一个 SM 最多能使用的寄存器个数为 64 K。如果我们 希望在一个 SM 中驻留最多的线程（2048 个），核函数中的每个线程最多只能用 32 个 寄存器。当每个线程所用寄存器个数大于 64 时，SM 的占有率将小于 50%。对于图灵架构，同样的占有率允许使用更多的寄存器。

- **有限的共享内存对占有率的约束情况**:此时，一个线程块最多能使用 3 KB 的共享内 存。在不改变线程块大小的情况下，要达到 50% 的占有率，一个线程块最多能使用 6KB 共享内存。

 在 CUDA 工具箱中，有一个名为CUDA_Occupancy_Calculator.xls 的 Excel文档，可用来计算各种情况下的SM占有率。


[^1]: 这里，全局的含义与 C++ 中全局变量的含义相同
[^2]: [CUDA 编程：基础与实践_樊哲勇, 页面 74](files/books/MLSys/CUDA%20编程：基础与实践_樊哲勇.pdf#page=74&selection=64,0,64,5)
[^3]: [CUDA 编程：基础与实践_樊哲勇, 页面 76](files/books/MLSys/CUDA%20编程：基础与实践_樊哲勇.pdf#page=76)
[^4]: 可以通过[CUDA 编程：基础与实践_樊哲勇, 页面 81](files/books/MLSys/CUDA%20编程：基础与实践_樊哲勇.pdf#page=81&selection=130,10,130,15)来查询cuda设备信息。
