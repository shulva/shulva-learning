# 线程束


> [!question] 线程束的作用
>  **线程块（Thread Block）是为程序员设计的逻辑分组，而线程束（Warp）是为硬件设计的物理执行单元。线程束的存在是为了极致的硬件效率。**
>  
>  硬件将32个线程捆绑成一个**线程束 (Warp)**。
> - 整个Warp共享**一套**指令获取和解码单元。
> - 硬件只需获取**一条**指令，解码**一次**。
> - 然后将这条指令**广播**给Warp中的32个线程，让它们在各自的数据上同时执行。
> 如果每个线程都需要自己的指令获取和解码逻辑，那么控制逻辑单元将占据巨大的芯片面积和功耗，留给实际计算单元的空间就所剩无几了。
> 
> 而且，一个SM上可能同时驻留着很多个线程。如果硬件调度器需要跟踪和调度每一个独立的线程，调度逻辑会变得异常复杂。
> 
> - **线程束的解决方案**：调度器不以线程为单位，而是以**Warp**为单位。对于SM来说，它只需要管理几十个Warp（例如 2048 / 32 = 64个Warp）。当一个Warp因为等待内存数据而停顿时，调度器可以立刻将另一个**准备就绪的Warp**换上来执行。这种切换是零开销的，能完美地隐藏内存延迟。
> 
> 所以，线程束将调度问题的规模缩小了32倍，使得硬件设计更简单、高效。
> 
> **线程束是内存合并的基础**:当一个Warp中的32个线程访问**连续的**内存地址时（例如线程i访问地址A+i），硬件可以将这32个零散的请求合并成一次或少数几次大的内存事务来完成。这比发起32次独立的内存请求要快得多。
> 
> |          | 线程块 (Thread Block)   | 线程束 (Warp)         |
> | -------- | -------------------- | ------------------ |
> | **角色**   | **逻辑分组** (为程序员服务)    | **物理执行单元** (为硬件服务) |
> | **目的**   | 资源管理、任务划分、线程协作       | 硬件效率、指令吞吐量、内存性能    |
> | **关键特性** | 共享内存、__syncthreads() | SIMT执行、内存合并、调度单元   |
> | **规模**   | 程序员定义 (可变，最大1024)    | 硬件固定 (32个线程)       |
> 所以，线程块和线程束不是互相替代的关系，而是两个不同层面的抽象，缺一不可。**线程块让程序员能方便地组织成千上万的线程协同工作，而线程束则让硬件能以极高的效率去执行这些线程。**

### SM与SIMT

从硬件上来看，一个 GPU 被分为若干个流多处理器（SM）。在同一个架构中，不同型号的 GPU 可以有不同数目的 SM。核函数中定义的线程块在执行时将被分配到还没有完全占满的 SM 中。一个线程块不会被分配到不同的 SM 中，但一个 SM 可以有一个或多个线程块。不同的线程块之间可以并发或顺序地执行，一般来说不能同步。

从更细的粒度看，**一个 SM 以 32 个线程为单位产生、管理、调度、执行线程**。这样的32个线程称为一个线程束。一个 SM 可以处理一个或多个线程块。一个线程块又可分为若干个线程束。例如，一个 128 线程的线程块将被分为 4 个线程束，其中每个线程束包含 32 个具有连续线程号的线程。这样的划分对所有的 GPU 架构都是成立的。

在同一时刻，一个线程束中的线程只能执行一个共同的指令或者闲置，这称为**单指令-多线程（single instruction, multiple thread，SIMT）**的执行模式。

当一个线程束中的线程顺序地执行判断语句中的不同分支时，我们称发生了**分支发散 （branch divergence）**。例如，假如核函数中有如下判断语句：
```cpp
if(condition) a;
else b;
```

首先，满足condition的线程会执行语句 A，其他的线程将闲置。然后，不满足condition的线程会执行语句 B，其他的线程将闲置。这样，当语句 A 和语句 B 的指令数差不多时，整个线程束的执行效率就比没有分支的情形低一倍。值得强调的是，**分支发散是针对同一个线程束内部的线程的**。

一个Warp的起始threadIdx.x（在1D线程块中）或者说线程在一维索引下的ID**一定是32的整数倍**。
如果不同的线程束执行条件语句的不同分支，则不属于分支发散。我们考察核函数中的如下代码段（假如线程块大小是 128）：

```cpp
int warp_id = threadIdx.x / 32; 
switch (warp_id) 
{ 
	case 0 : S0; break; 
	case 1 : S1; break; 
	case 2 : S2; break; 
	case 3 : S3; break; 
}
//若将上述代码段改写成如下形式：
int lane_id = threadIdx.x % 32;
```

则将导致严重的分支发散，因为变量 `lane_id`在同一个线程束内部可以取 32 个不同的值。

一般来说，在编写核函数时要尽量避免分支发散。但是在很多情况下，根据算法的需求，是无法完全避免分支发散的。

如果一个判断语句的两个分支中有一个分支不包含指令，那么即使发生了分支发散也不会显著地影响程序性能。总之，**须把程序的正确性放在第一位，不能因为担心发生分支发散而不敢写判断语句。**

从伏特架构开始，引入了独立线程调度（independent thread scheduling）机制。每个线程有自己的程序计数器。这使得伏特架构有了一些以前的架构所没有的新的线程束内同步与通信的模式，从而提高了编程的灵活性。

要实现独立线程调度机制，一个代价是增加了寄存器负担：单个线程的程序计数器一般需要使用两个寄存器。也就是说，伏特架构的独立线程调度机制使得SM中每个线程可利用的寄存器少了两个。

> [!question]  Volta之前和之后的SIMT模型
> 在Pascal及更早的架构中，Warp（32个线程）的执行是**严格同步（Lockstep）**的
> 1. **统一的程序计数器（Program Counter, PC）**：整个Warp共享一个程序计数器。这意味着所有32个线程在任何时刻都必须执行相同的指令。
> 2. **分支发散的处理**：当遇到分支（如if-else）时，如果Warp内的线程选择不同路径，就会发生分支发散。
 >   - 硬件会选择一条路径（例如if块），将走这条路的线程设为“活动”，另一条路的线程设为“屏蔽”（inactive）。
 >   - 执行完第一条路径后，硬件再切换，将之前被屏蔽的线程设为“活动”，执行第二条路径。
 >   - **关键限制**：在执行一条分支路径时，另一条路径上的线程是完全静止的，无法做任何事情，它们只能等待。
 > ---
 > 改动后：
 > 1. **每个线程拥有独立的程序计数器（PC）**：这是最核心的改变。Warp内的每个线程现在都有自己的PC和调用栈（call stack）。这意味着它们可以各自在代码的不同位置执行。（代价是增加了寄存器负担）。
>2. **调度器维护线程状态**：硬件调度器现在会跟踪Warp中每个线程的状态（例如，准备就绪、等待内存、等待同步等）。它不再强制所有线程执行同一指令。
>3. **分支发散的处理方式改变**：
>    - 当发生分支发散时，线程不再是简单地被“屏蔽”。
>    - 走if路径的线程和走else路径的线程都处于“准备就绪”状态。
>    - 调度器会选择一组**路径相同**的线程来执行。例如，它可能会先执行所有选择if路径的线程，当这些线程遇到暂停点（如等待内存I/O）时，调度器**可以立即切换到**执行那些选择else路径的线程，而不需要等待if路径完全执行完毕。

这样使得：
1. **编程模型大大简化**：程序员不再需要担心Warp内的隐式同步和死锁问题。可以编写更自然、更灵活的代码。
2. **更高的资源利用率**：通过在发散的分支之间灵活切换，硬件可以更好地隐藏延迟，保持计算单元的繁忙，从而提升性能。

### 加速-线程同步函数[^1]

在我们的归约问题中，当所涉及的线程都在一个线程束内时，可以将线程块同步函数 `__syncthreads` 换成一个更加廉价的线程束同步函数 `__syncwarp`。我们将它简称为束内同步函数。

该函数的原型为 `void __syncwarp(unsigned mask = 0xffffffff);`

该函数有一个可选的参数mask。该参数是一个代表掩码的无符号整型数，默认值的全部 32 个二进制位都为 1，代表线程束中的所有线程都参与同步。如果要排除一些线程，可以用一个对应的二进制位为 0 的掩码参数。例如，掩码 0xfffffffe 代表排除第 0 号线程。

例如[改进过后的规约函数中](files/books/MLSys/CUDA%20编程：基础与实践_樊哲勇.pdf#page=122&selection=10,2,10,4),当 offset <= 16 时，我们在每一次折半求和后使用束内同步函数 `__syncwarp`。当 offset >= 32 时，和原来一样，我们在每一次折半求和后使用线程块同步函数 `__syncthreads`

相比之前的核函数，该版本的核函数大概快了 10%。可见，束内同步函数 `__syncwarp` 确实比线程块同步函数 `__syncthreads` 高效。

```cpp
for (int offset = blockDim.x>>1;offset>=32;offset >>= 1)
{
	if (tid < offset)
	{
		s_y[tid] += s_y[tid + offset];
	}
	__syncthreads();
}

for (int offset = 16; offset > 0; offset >>= 1)
   {
       if (tid < offset)
       {
           s_y[tid] += s_y[tid + offset];
       }
       __syncwarp();
  }
```

这些涉及到多线程的数据读写问题需要注意[读-写竞争问题](files/books/MLSys/CUDA%20编程：基础与实践_樊哲勇.pdf#page=123&selection=113,7,119,0)。

### 线程束内的基本函数

这里仅介绍线程束表决函数和线程束洗牌函数。

以下函数中， mask 称为掩码，是一个无符号整数，具有 32 位。这 32 个二进制位从右边数起刚好对应线程束内的 32 个线程。

掩码用于指定将要参与计算的线程：当掩码中的一个二进制位为 1 时，代表对应的线程参与计算；当掩码中的一个二进制位为 0 时，代表忽略对应的线程。特别地，各种函数返回的结果对被掩码排除的线程来说是没有定义的。所以，不要尝试在这些被排除的线程中使用函数的返回值。

以下每个线程束洗牌函数的最后一个参数 w 都是可选的，有默认值 warpSize，在当前所有架构的 GPU中都是 32。

参数 w 只能取 2、 4、8、16、32 这 5 个整数中的一个。当 w 小于 32 时，就相当于（逻辑上的）线程束大小是 w，而不是 32，其他规则不变。对于一般的情况，可以定义一个“束内指标”（假设使用一维线程块）:
`int lane_id = threadIdx.x & (w - 1);`

在使用线程束内的函数时都需要注意线程指标和束内指标的对应关系。[^3]

| 函数名称                           | 功能描述                                                               | 返回值          | 关键参数说明                                          |
| ------------------------------ | ------------------------------------------------------------------ | ------------ | ----------------------------------------------- |
| __ballot_sync(mask, pred)      | 聚合Warp内各参与线程的布尔状态。若参与线程n的pred非零，则返回整数的第n位置1，否则置0。                  | unsigned int | **pred**: 一个布尔条件表达式。                            |
| __all_sync(mask, pred)         | 对Warp内所有参与线程的pred值执行逻辑与（AND）规约。仅当所有参与线程的pred都非零时，才返回1。             | int (1 或 0)  | **pred**: 一个布尔条件表达式。                            |
| __any_sync(mask, pred)         | 对Warp内所有参与线程的pred值执行逻辑或（OR）规约。只要有至少一个参与线程的pred非零，就返回1。             | int (1 或 0)  | **pred**: 一个布尔条件表达式。                            |
| **Warp内数据移动 (Shuffle)**        |                                                                    |              |                                                 |
| __shfl_sync(mask, v, src)      | 从一个指定的源线程src读取其变量v的值，并将其广播给Warp内所有参与线程。                            | 变量v的类型       | **v**: 要传输的变量。<br>**src**: 源线程在Warp中的ID (0-31)。 |
| __shfl_up_sync(mask, v, d)     | 将数据在Warp内向上移动d个位置。线程t接收来自线程t-d的变量v的值。若t-d < 0，则该线程接收自己的v值。         | 变量v的类型       | **v**: 要传输的变量。<br>**d**: 向上移动的距离/偏移量。           |
| __shfl_down_sync(mask, v, d)   | 将数据在Warp内向下移动d个位置。线程t接收来自线程t+d的变量v的值。若t+d >= warpSize，则该线程接收自己的v值。 | 变量v的类型       | **v**: 要传输的变量。<br>**d**: 向下移动的距离/偏移量。           |
| __shfl_xor_sync(mask, v, lane) | 在Warp内进行异或模式的数据交换。线程t接收来自线程t ^ lane的变量v的值。                         | 变量v的类型       | **v**: 要传输的变量。<br>**lane**: 用于计算源线程ID的异或掩码。     |

---


使用这些函数时不需要在任何地方明显地使用同步函数，如`__syncwarp`。这是因为，这里所有的线程束内的基本函数（都以 `_sync` 结尾）都具有隐式的同步功能。

### 加速-线程束函数[^2]

```cpp
for (int offset = blockDim.x>>1;offset>=32;offset >>= 1)
{
	if (tid < offset)
	{
		s_y[tid] += s_y[tid + offset];
	}
	__syncthreads();
}

real y = s_y[tid];

for (int offset = 16; offset > 0; offset >>= 1)
{
	y += __shfl_down_sync(FULL_MASK, y, offset);
}

//其他线程束如32-63的y无意义，舍弃
if (tid == 0) { atomicAdd(d_y, y); } 
```

 相比之前的版本，我们发现两处不同。
 
 第一，在进行线程束内的循环之前，这里将共享内存中的数据复制到了寄存器。在线程束内使用洗牌函数进行规约时，不再需要明显地使用共享内存，寄存器是肯定比共享内存更高效的。

第二，用语句 `y += __shfl_down_sync(FULL_MASK, y, offset);`替换了原来的部分。也就是说，去掉了同步函数，也去掉了对线程号的限制，因为洗牌函数能够自动处理同步与读-写竞争问题。对全部参与的线程来说，上述洗牌函数总是先读取各个线程中 y 的值，再将洗牌操作的结果写入各个线程中的 y。

继续在 GeForce RTX 2070 中测试，结果显示使用线程束洗牌函数的核函数相对于使用束内同步函数的核函数有 20% 的性能提升。

### 协作组与线程块片

通过前面的学习，我们知道，在有些并行算法中，需要若干线程间的协作。要协作，就必须要有同步机制。

协作组（cooperative groups）可以看作是线程块和线程束同步机制的推广，它提供了更为灵活的线程协作方式，包括线程块内部的同步与协作、线程块之间的（网格级的）同步与协作及设备之间的同步与协作。

目前，网格级的协作组功能非常有限，而且使用中有很多限制，故也不讨论。所以仅讲解线程块级的协作组。

使用协作组的功能时需要在相关源文件包含如下代码:

```cpp
#include <cooperative_groups.h> 
using namespace cooperative_groups; //命名空间
namespace cg = cooperative_groups; //也可以起别名使用
```

协作组编程模型中最基本的类型是线程组thread_group。该类型有一些函数成员[^4]。

线程组类型有一个称为线程块 thread_block 的导出类型,可以用如下方式定义并初始化一个 thread_block 对象:

其中，this_thread_block() 相当于一个线程块类型的常量。这样定义的 g 就代表线程块，只不过这里把它包装成了一个类型。

```cpp
thread_block g = this_thread_block();
g.sync(); //等价于__syncthreads()
g.size(); //g中线程的数量

//等价CUDA中的内建变量 threadIdx
int threadIdx = g.thread_index();
//等价CUDA中的内建变量 blockIdx
int blockIdx = g.group_index();
```

可以用函数 `tiled_partition` 将一个线程块划分为若干片（tile），每一片构成一个新的线程组。目前仅仅可以将片的大小设置为 2 的正整数次方且不大于 32，也就是 2、 4、8、16 和 32（和线程束洗牌函数的最后一个参数类似） 。

例如，如下语句通过函数 `tiled_partition` 将一个线程块分割为线程束:

```cpp
thread_group g32 = tiled_partition(this_thread_block(), 32);
thread_group g4 = tiled_partition(g32, 4);//更细的分割
```

当这种线程组的大小在编译期间就已知时，可以用如下模板化的版本（可能更加高效） 进行定义：

```cpp
thread_block_tile<32> g32 = tiled_partition<32>(this_thread_block()); 

thread_block_tile<4> g4 = tiled_partition<4>(this_thread_block());
```

这样定义的线程组一般称为线程块片（thread block tile）。线程块片还额外地定义了如下函数（类似于线程束内的基本函数）：

```cpp
unsigned __ballot_sync(int predicate); 
int __all_sync(int predicate); 
int __any_sync(int predicate); 
T __shfl_sync(T v, int srcLane); 
T __shfl_up_sync(T v, unsigned d); 
T __shfl_down_sync(T v, unsigned d); 
T __shfl_xor_sync(T v, int laneMask);
```

线程块片的函数有两点不同。

第一，线程块片的函数少了第一个代表掩码的参数mask，因为线程组内的所有线程都必须参与相关函数的运算；

第二，线程块片的洗牌函数（上述函数中的后 4 个）少了最后一个代表宽度的参数w，因为该宽度就是线程块片的大小，即定义线程块片的模板参数。

所以，上面的代码也可以改写成这样。使用协作组的核函数和使用线程束洗牌函数的核函数具有等价的执行效率。

```cpp
    thread_block_tile<32> g = tiled_partition<32>(this_thread_block());
    
    for (int i = g.size() >> 1; i > 0; i >>= 1)
    {
        y += g.shfl_down(y, i);
    }
```

### 加速-提高线程利用率[^5]

可以看出，在循环中，线程的利用率是越来越低的(1/2,1/4....)。相比之下，在归约之前，将全局内存中的数据复制到共享内存的操作对线程的利用率是 100% 的。

```cpp
    s_y[tid] = (n < N) ? d_x[n] : 0.0;
    __syncthreads();

    for (int offset=blockDim.x>>1;offset>=32; offset >>= 1)
    {
        if (tid < offset)
        {
            s_y[tid] += s_y[tid + offset];
        }
        __syncthreads();
    }
```

据此得到一个想法：如果能够提高归约之前所做计算的比例，那应该可以从整体上提升对线程的利用率。

在上一个版本，共享内存数组中的每一个元素（注意，不同的线程块有不同的共享内存变量副本）仅仅保存了一个全局内存数组的数据。为了提高归约之前所做计算的比例，我们可以**在归约之前将多个全局内存数组的数据累加到一个共享内存数组的一个元素中**。

为了做到这一点，我们可以让每个线程处理若干个数据。这里要注意的是，千万不要让一个线程处理相邻的若干数据，因为这必然导致全局内存的非合并访问。

要保证全局内存的合并访问，在我们的问题中必须让相邻的线程访问相邻的数据，而同一个线程所访问的数据之间必然具有某种跨度。该跨度可以是一个线程块的线程数，也可以是整个网格的线程数。

```cpp
const int N = 100000000;
const int BLOCK_SIZE = 128;
const int GRID_SIZE = 10240;

//.....
//
real y = 0.0;
const int stride = blockDim.x * gridDim.x;//128*10240

//第一次调用核函数
//1310720个线程以stride在d_x数组中跨越并累加值进入y中
//100000000个数被累加进1310720个线程的部分和中
for (int n = bid * blockDim.x + tid; n < N; n += stride)
{
	y += d_x[n];
}
s_y[tid] = y;
__syncthreads();

//块内规约
for (int offset = blockDim.x>>1;offset>= 32; offset >>= 1)
{
	if (tid < offset)
	{
		s_y[tid] += s_y[tid + offset];
	}
	__syncthreads();
}

y = s_y[tid];

thread_block_tile<32> g = tiled_partition<32>(this_thread_block());

//最后，块内的128个线程的部分和进入y中
for (int i = g.size() >> 1; i > 0; i >>= 1)
{
	y += g.shfl_down(y, i);
}

//最后，每一个块中的线程和进入d_y
if (tid == 0)
{
	d_y[bid] = y;
}

```

```cpp
const int BLOCK_SIZE = 128;
const int GRID_SIZE = 10240;
//....

//外层调用两次核函数
CHECK(cudaMalloc(&d_y, ymem));
reduce_cp<<<GRID_SIZE, BLOCK_SIZE, smem>>>(d_x, d_y, N);

//流程相同，只有一个线程块，最后结果写入d_y[0]
reduce_cp<<<1, 1024, sizeof(real) * 1024>>>(d_y, d_y, GRID_SIZE);
```

测试后发现其相比之前的最优版本有了 40% 的性能提升。更重要的是，该程序归约的结果 为 123000064.0，相对于精确结果（123000000.0）有 7 位准确的有效数字。相比之下，之前 使用原子函数时所得到的结果（123633392.0）仅有 3 位准确的有效数字。

这是因为，在使用两个核函数时，将数组 d_y 归约到最终结果的计算也使用了折半求和，比直接累加（使用原子函数或复制到主机再累加的情形）要稳健。

### 加速-避免反复分配与释放设备内存[^6]

在上面的包装函数 reduce 中，我们需要为数组 d_y 分配与释放设备内存。实际上，设备内存的分配与释放是比较耗时的。

一种优化方案是使用静态全局内存代替这里的动态全局内存。因为静态内存是编译期间就会分配好的，不会在运行程序时反复地分配，故比动态内存分配高效很多。

如果不想改变核函数代码，可以利用运行时API函数 `cudaGetSymbolAddress`获得一个指向该静态全局内存的指针供核函数使用。函数原型如下：
`cudaError_t cudaGetSymbolAddress(void **devPtr, const void *symbol);`其的作用为：

1. **查找符号 static_y 在GPU设备上的内存地址**。编译器和CUDA运行时知道 static_y 这个符号（Symbol）被分配在GPU内存的哪个具体位置。
2. **将这个GPU内存地址的值，复制到CPU端的指针 devPtr 中**。

这里的symbol参数可以是静态全局内存（用 `__device__`定义）或者常量内存（用 `__constant__` 定义）的变量名。

```cpp
//可以用如下语句在函数外部定义我们需要的静态全局内存变量
__device__ real static_y[GRID_SIZE];

real reduce(const real *d_x)
{
    real *d_y;
    
	//获取static_y的地址并存入d_y
	//原来使用cudaMalloc分配
    CHECK(cudaGetSymbolAddress((void**)&d_y, static_y));
    
    const int smem = sizeof(real) * BLOCK_SIZE;

    reduce_cp<<<GRID_SIZE, BLOCK_SIZE, smem>>>(d_x, d_y, N);
    reduce_cp<<<1, 1024, sizeof(real) * 1024>>>(d_y, d_y, GRID_SIZE);

    real h_y[1] = {0};
    CHECK(cudaMemcpy(h_y, d_y, sizeof(real), cudaMemcpyDeviceToHost));
    // CHECK(cudaMemcpyFromSymbol(h_y, static_y, sizeof(real)); // also ok

    return h_y[0];
}
```

通过函数` cudaGetSymbolAddress` 获得的设备指针可以像其他设备指针一样使用。除了可以将该指针传入核函数之外，还可以利用它进行主机和设备之间的数据传输`cudaMemcpy`。

这样修改之后，归约函数的计算时间从约 2.0 ms 缩减到约 1.5 ms。该测试结果说明全局内存变量的动态分配确实比较耗时。

总之，除在适当的情况下使用静态全局内存替换动态全局内存外，还要尽量避免在较内层循环反复地分配与释放设备内存。

![](../../../../../files/images/MLsys/13-a-6-3.png)


[^1]: https://github.com/brucefan1983/CUDA-Programming/blob/master/src/10-warp/reduce.cu#L94

[^2]: https://github.com/brucefan1983/CUDA-Programming/blob/master/src/10-warp/reduce.cu#L94

[^3]: [CUDA 编程：基础与实践_樊哲勇, 页面 125](files/books/MLSys/CUDA%20编程：基础与实践_樊哲勇.pdf#page=125&selection=113,0,113,13)

[^4]: [CUDA 编程：基础与实践_樊哲勇, 页面 132](files/books/MLSys/CUDA%20编程：基础与实践_樊哲勇.pdf#page=132&selection=100,7,100,9)

[^5]: https://github.com/brucefan1983/CUDA-Programming/blob/master/src/10-warp/reduce1parallelism.cu

[^6]: https://github.com/brucefan1983/CUDA-Programming/blob/master/src/10-warp/reduce2static.cu
