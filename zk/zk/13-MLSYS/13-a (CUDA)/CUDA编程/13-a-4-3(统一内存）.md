# 统一内存

统一内存是一种逻辑上的概念，它既不是显存，也不是主机的内存，而是一种系统中的任何处理器（CPU 或 GPU）都可以访问，并能保证一致性的虚拟存储器。这种虚拟存储器是通过 CPU 和 GPU 各自内部集成的内存管理单元（memory management unit）实现的。 在某种程度上，可以将一个系统中某个处理器的内存看成整个统一内存的超级大缓存。

> [!NOTE] 统一内存的优点
> - 统一内存使 CUDA 编程更加简单。使用统一内存，将**不再需要手动将数据在主机与设备之间传输**，也不需要针对同一组数据定义两个指针，并分别分配主机和设备内存。 对于某个统一内存变量，可以直接从 GPU 或者 CPU 中进行访问。
> - 可能会提供比手工移动数据提供更好的性能。底层的统一内存实现，**可能会自动将一部分数据放置到离某个存储器更近的位置**（如部分放置到某卡的显存中，部分放置到内存中），这种自动的就近数据存放，有可能会提升性能。
> - 允许 GPU 在使用了统一内存的情况下，进行超量分配。**超出 GPU 内存额度的部分存放在主机上**。这可能是使用统一内存时最大的好处，因为一般来说 CPU 的内存可以更多，但处理速度较低，而 GPU 虽然处理速度较高，但内存（显存）数量有限 。

统一内存在设备中是当作全局内存使用的，而且必须在主机端定义或分配内存，而不能在设备端（核函数和 `__device__` 函数）定义或分配内存。

### 动态统一内存

```cpp
int main(void)
{
	//.................
    CHECK(cudaMallocManaged((void **)&x, M));
    CHECK(cudaMallocManaged((void **)&y, M));
    CHECK(cudaMallocManaged((void **)&z, M));

	//分配了统一内存的变量既可以被设备访问，也可以被主机访问。
    for (int n = 0; n < N; ++n)
    {
        x[n] = a;
        y[n] = b;
    }

    const int block_size = 128;
    const int grid_size = N / block_size;
	
	//分配了统一内存的变量既可以被设备访问，也可以被主机访问。
    add<<<grid_size, block_size>>>(x, y, z);

    CHECK(cudaDeviceSynchronize());
    check(z, N);

    CHECK(cudaFree(x));
    CHECK(cudaFree(y));
    CHECK(cudaFree(z));
    return 0;
}
```

相比 `cudaMalloc` 函数，`cudaMallocManaged`函数多了一个可选参数`flags`。该参数的默认值是`cudaMemAttachGlobal`。如果取默认值，代表分配的全局内存可由任何设备通过任何 CUDA 流访问。

### 静态统一内存

正如 GPU 中的全局内存除可以动态分配外，还可以静态分配，统一内存也可以静态地分配。要定义静态统一内存，只需要在修饰符` __device__ `的基础上再加上修饰符` __managed__ `即可。注意，这样的变量是在任何函数外部定义的，可见范围是所在源文件（更准确地说是所在翻译单元）。

```cpp
__device__ __managed__ int ret[1000];
```

### 使用统一内存申请超量的内存

使用统一内存的一个好处是在适当的时候可以超量申请设备内存。
 对于第二代统一内存来说， 函数 `cudaMallocManaged `的成功调用只代表成功地预定了一段地址空间，而统一内存的实际分配则发生在主机或者设备第一次访问预留的内存时。

```cpp

const int N = 30;

void cpu_touch(uint64_t *x, size_t size)
{
    for (size_t i = 0; i < size / sizeof(uint64_t); i++) 
    {
        x[i] = 0;
    }
}

int main(void)
{
    for (int n = 1; n <= N; ++n)
    {
        size_t size = size_t(n) * 1024 * 1024 * 1024;
        uint64_t *x;
        CHECK(cudaMallocManaged(&x, size));
        cpu_touch(x, size);
        CHECK(cudaFree(x));
        printf("Allocated %d GB unified memory with CPU touch.\n", n);
    }
    return 0;
}
```

在主函数中，我们在调用`cudaMallocManaged`分配统一内存之后，在调用 `cudaFree `释放统一内存之前，调用了自定义的 `cpu_touch `函数让主机对统一内存中的数据进行初始化。

编译后运行该程序，结果显示最多能成功分配 13 GB 的统一内存，之后抛出一个错误信息“Killed”。这说明，仅仅在CPU中访问统一内存的话，在使用完主机内存后不会自动使用设备内存。所以，若要将主机和设备的内存都纳入统一内存，则需要及时地让GPU访问统一内存或者用`cudaMemPrefetchAsync `函数实现数据从主机到设备的迁移。

### 优化

为了在使用统一内存时获得较高性能，需要避免缺页异常、保持数据的局部性（让相关数据尽量靠近对应的处理器）且避免内存抖动（即频繁地在不同的处理器之间传输数据）。 CUDA 的统一内存机制可以部分地自动做到这些，但很多情况下还是需要手动地给编译器一些提示（hints），如使用 CUDA 运行时函数 `cudaMemAdvise` 和`cudaMemPrefetchAsync`

函数 `cudaMemPrefetchAsync` 的原型如下：

```cpp
cudaError_t cudaMemPrefetchAsync 
(
	const void *devPtr, 
	size_t count,
	int dstDevice, 
	cudaStream_t stream 
)	
```

该函数的作用是在 CUDA流 stream 中将统一内存缓冲区 devPtr内 count数的字节的内存迁移到设备 dstDevice（主机的设备号用 cudaCpuDeviceId 表示）中的内存区域，从而防止（或减少）缺页异常，并提高数据的局部性。

一般来说，在使用统一内存时，要尽可能多地使用 `cudaMemPrefetchAsync` 函数，将缺页异常的次数最小化。

```cpp
int main(void)
{
    int device_id = 0;
    CHECK(cudaGetDevice(&device_id));
	  
    const int N = 100000000;
    const int M = sizeof(double) * N;
    double *x, *y, *z;
    CHECK(cudaMallocManaged((void **)&x, M));
    CHECK(cudaMallocManaged((void **)&y, M));
    CHECK(cudaMallocManaged((void **)&z, M));

    for (int n = 0; n < N; ++n)
    {
        x[n] = a;
        y[n] = b;
    }

    const int block_size = 128;
    const int grid_size = N / block_size;

	//实现统一内存从主机到设备的迁移
    CHECK(cudaMemPrefetchAsync(x, M, device_id, NULL));
    CHECK(cudaMemPrefetchAsync(y, M, device_id, NULL));
    CHECK(cudaMemPrefetchAsync(z, M, device_id, NULL));
    
    add<<<grid_size, block_size>>>(x, y, z);
    
	//实现统一内存从设备到主机的迁移
    CHECK(cudaMemPrefetchAsync(z, M, cudaCpuDeviceId, NULL));

    CHECK(cudaDeviceSynchronize());
    check(z, N);

    CHECK(cudaFree(x));
    CHECK(cudaFree(y));
    CHECK(cudaFree(z));
    return 0;
}
```

CUDA统一内存将缺页异常这个概念应用到了CPU和GPU之间，如果cpu访问一个在gpu上的数据页，或是gpu访问一个在cpu上的数据页，就会触发缺页异常。这会触发cpu系统内存和gpu显存的数据迁移，代价较高。

> [!NOTE] cudaMemPrefetchAsync的作用 
> 
> - **模式**: 主动、预先、指令式 (Proactive)。
> - **过程**:
>     1. 在启动GPU Kernel**之前**，你作为程序员，已经预知到这个Kernel将会需要某块数据。
>     2. 你调用 cudaMemPrefetchAsync，把数据准备好，搬到指定的地方去
>     3. CUDA驱动接收到命令后，会**异步地**启动数据传输。因为是异步的，CPU可以继续执行后续代码（比如提交更多的预取任务，或者启动Kernel）。
>     4. 当你真正启动GPU Kernel时，很大概率上数据已经到达或者正在到达GPU显存的途中。
>     5. Kernel运行时直接从本地显存访问数据，**不会触发缺页异常，也就没有了那段高昂的暂停延迟**。
>         
> - **优势**: 通过将数据传输与其它操作（如其它数据块的传输，或后续的计算）**重叠（Overlap）**，成功地**隐藏了数据传输的延迟**。
